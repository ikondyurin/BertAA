{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for collecting explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = [4433, 7582, 2457, 2291, 6345, 6737, 2662, 3839, 5039, 7304, 6388, 2813, 2869, 6150, 2665, 1756, 4589, \n",
    "6286, 4001, 1596, #20\n",
    " 4817, 2261, 7292, 2595, 128, 3533, 2443, 6652, 3820, 796, 3518, 110, 575, 4142, 1950, 1216, 2084, 2534, 3291, 4807, 2269,\n",
    " 3625, 1154, 5049, 5653, 5924, 2366, 3425, 1821, 3610, 348, 2181, 6432, 7560, 6981, 5382, 3898, 2889, 4019, 80, \n",
    "5578, 3515, 3151, 4652, 1838, 2447, 2319, 763, 2963, 1914, 5210, 5609, 2609, 3915, 4370, 6654, 5096, 3640, 3634, 3073, 3092, \n",
    "794, 695, 4275, 757, 4527, 5194, 421, 2121, 649, 2306, 3796, 4805, 6340, 2930, 3963, 7422, 4290, 736, 900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(\"D:\\pan20-authorship-verification-training-small\\pan20-authorship-verification-training-small.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'fandoms', 'pair'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([7292], dtype='int64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.iloc[50285]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48333    [Star Wars Rebels, Xena: Warrior Princess]\n",
      "Name: fandoms, dtype: object\n",
      "33971    [Shakugan no Shana, Riddle Story of Devil/悪魔のリドル]\n",
      "Name: fandoms, dtype: object\n",
      "22263    [House, M.D., StarTrek: The Next Generation]\n",
      "Name: fandoms, dtype: object\n",
      "45410    [Batman Beyond, Flame of Recca]\n",
      "Name: fandoms, dtype: object\n",
      "26226    [Home Improvement, X-Men]\n",
      "Name: fandoms, dtype: object\n",
      "28706    [Waterloo Road, Injustice: Gods Among Us]\n",
      "Name: fandoms, dtype: object\n",
      "10476    [JoJo's Bizarre Adventure, Kuroko no Basuke/黒子...\n",
      "Name: fandoms, dtype: object\n",
      "46702    [Hyperdimension Neptunia, Silence of the Lambs...\n",
      "Name: fandoms, dtype: object\n",
      "945    [Final Fantasy X, Mega Man]\n",
      "Name: fandoms, dtype: object\n",
      "15777    [Beetlejuice, Biker Mice From Mars]\n",
      "Name: fandoms, dtype: object\n",
      "25514    [Biker Mice From Mars, Fushigi Yuugi]\n",
      "Name: fandoms, dtype: object\n",
      "28702    [Waterloo Road, Sin City]\n",
      "Name: fandoms, dtype: object\n",
      "39696    [21 Jump Street, In Plain Sight]\n",
      "Name: fandoms, dtype: object\n",
      "22231    [Riddle Story of Devil/悪魔のリドル, Undertale]\n",
      "Name: fandoms, dtype: object\n",
      "33743    [Covert Affairs, Blindspot]\n",
      "Name: fandoms, dtype: object\n",
      "52061    [X-Men: The Movie, Ouran High School Host Club]\n",
      "Name: fandoms, dtype: object\n",
      "10709    [American Idiot, Kingdom Hearts]\n",
      "Name: fandoms, dtype: object\n",
      "27635    [Dresden Files, Life on Mars]\n",
      "Name: fandoms, dtype: object\n",
      "28529    [Haibane Renmei, Adventures of Sinbad]\n",
      "Name: fandoms, dtype: object\n",
      "47565    [Grand Theft Auto, Hikaru no Go]\n",
      "Name: fandoms, dtype: object\n",
      "23808    [Dungeons and Dragons, Star Fox]\n",
      "Name: fandoms, dtype: object\n",
      "39039    [Story of Tracy Beaker, Katawa Shoujo]\n",
      "Name: fandoms, dtype: object\n",
      "50285    [Naruto, Harry Potter]\n",
      "Name: fandoms, dtype: object\n",
      "2366    [Chrono Crusade, Fullmetal Alchemist]\n",
      "Name: fandoms, dtype: object\n",
      "3175    [Grey's Anatomy, Popular]\n",
      "Name: fandoms, dtype: object\n",
      "14025    [Red Dawn, Underworld]\n",
      "Name: fandoms, dtype: object\n",
      "48487    [Scandal, White Collar]\n",
      "Name: fandoms, dtype: object\n",
      "27070    [Final Fantasy Agito XIII, Final Fantasy Versu...\n",
      "Name: fandoms, dtype: object\n",
      "30098    [Blue Dragon, Motorcity]\n",
      "Name: fandoms, dtype: object\n",
      "2627    [Kamikaze Kaitou Jeanne, Saki/咲]\n",
      "Name: fandoms, dtype: object\n",
      "50424    [Danny Phantom, Sonic the Hedgehog]\n",
      "Name: fandoms, dtype: object\n",
      "3894    [Excel Saga, Full Metal Panic]\n",
      "Name: fandoms, dtype: object\n",
      "50633    [Percy Jackson and the Olympians, Teen Titans]\n",
      "Name: fandoms, dtype: object\n",
      "21058    [Adventure Time with Finn and Jake, Hetalia - ...\n",
      "Name: fandoms, dtype: object\n",
      "6845    [Lost Boys, Newsies]\n",
      "Name: fandoms, dtype: object\n",
      "50548    [Power Rangers, Fire Emblem]\n",
      "Name: fandoms, dtype: object\n",
      "37797    [Toontown, You're Beautiful/미남이시네요]\n",
      "Name: fandoms, dtype: object\n",
      "22316    [Greek, Pretty Little Liars]\n",
      "Name: fandoms, dtype: object\n",
      "24395    [Law and Order: SVU, Women's Murder Club]\n",
      "Name: fandoms, dtype: object\n",
      "50166    [Sons of Anarchy, Sookie Stackhouse/Southern V...\n",
      "Name: fandoms, dtype: object\n",
      "12277    [Laurie R. King, Valdemar universe]\n",
      "Name: fandoms, dtype: object\n",
      "22736    [Judging Amy, SWAT Kats]\n",
      "Name: fandoms, dtype: object\n",
      "11813    [Once Upon a Time, Star Trek: 2009]\n",
      "Name: fandoms, dtype: object\n",
      "47281    [Hollyoaks, Magic Knight Rayearth/魔法騎士レイアース]\n",
      "Name: fandoms, dtype: object\n",
      "43455    [Claymore, All My Children]\n",
      "Name: fandoms, dtype: object\n",
      "17736    [Ghost Hunt, Ouran High School Host Club]\n",
      "Name: fandoms, dtype: object\n",
      "38992    [Katawa Shoujo, IT]\n",
      "Name: fandoms, dtype: object\n",
      "11676    [Alice, 2009, Glee]\n",
      "Name: fandoms, dtype: object\n",
      "3025    [Batman, ThunderCats]\n",
      "Name: fandoms, dtype: object\n",
      "31578    [Children of the Corn, Mabinogi]\n",
      "Name: fandoms, dtype: object\n",
      "725    [Garfield, MacGyver]\n",
      "Name: fandoms, dtype: object\n",
      "27869    [Boondock Saints, Never Back Down]\n",
      "Name: fandoms, dtype: object\n",
      "37483    [Bourne series, New Jedi Order]\n",
      "Name: fandoms, dtype: object\n",
      "17209    [Reign, Suite Life series]\n",
      "Name: fandoms, dtype: object\n",
      "44978    [Secret Life of the American Teenager, Moonlight]\n",
      "Name: fandoms, dtype: object\n",
      "38147    [Full House, L Word]\n",
      "Name: fandoms, dtype: object\n",
      "44812    [Ice Age, Megamind]\n",
      "Name: fandoms, dtype: object\n",
      "141    [Slayers, Xiaolin Showdown]\n",
      "Name: fandoms, dtype: object\n",
      "23961    [Adventure Time with Finn and Jake, RWBY]\n",
      "Name: fandoms, dtype: object\n",
      "31567    [Brave, 2017, Rango]\n",
      "Name: fandoms, dtype: object\n",
      "10275    [Durarara!!/デュラララ!!, Game of Thrones]\n",
      "Name: fandoms, dtype: object\n",
      "8610    [Underworld, Van Helsing]\n",
      "Name: fandoms, dtype: object\n",
      "26900    [Borgias, Clash of the Titans, 2010]\n",
      "Name: fandoms, dtype: object\n",
      "13515    [Adventure Quest, Clock Tower]\n",
      "Name: fandoms, dtype: object\n",
      "29057    [Penny Dreadful, Dance Academy]\n",
      "Name: fandoms, dtype: object\n",
      "11131    [Balto, Rise of the Guardians]\n",
      "Name: fandoms, dtype: object\n",
      "45706    [Moulin Rouge, X/1999]\n",
      "Name: fandoms, dtype: object\n",
      "9127    [Rush, 2008, Veronica Mars]\n",
      "Name: fandoms, dtype: object\n",
      "45205    [Kamen Rider, Earthbound]\n",
      "Name: fandoms, dtype: object\n",
      "4378    [Leverage, Teen Wolf]\n",
      "Name: fandoms, dtype: object\n",
      "14687    [Alice 19th, Card Captor Sakura]\n",
      "Name: fandoms, dtype: object\n",
      "17233    [Suite Life series, Wizards of Waverly Place]\n",
      "Name: fandoms, dtype: object\n",
      "42244    [Falling Skies, Sofia the First]\n",
      "Name: fandoms, dtype: object\n",
      "51363    [StarTrek: Voyager, Avatar: Last Airbender]\n",
      "Name: fandoms, dtype: object\n",
      "15931    [Lois and Clark, Tomb Raider]\n",
      "Name: fandoms, dtype: object\n",
      "1107    [Batman, Kuroshitsuji]\n",
      "Name: fandoms, dtype: object\n",
      "11092    [Early Edition, Escaflowne]\n",
      "Name: fandoms, dtype: object\n",
      "12874    [Stargate: SG-1, X-Files]\n",
      "Name: fandoms, dtype: object\n",
      "8977    [Devil May Cry, Primeval]\n",
      "Name: fandoms, dtype: object\n",
      "13326    [Incredible Hulk, X-Men]\n",
      "Name: fandoms, dtype: object\n",
      "38102    [Full House, North and South]\n",
      "Name: fandoms, dtype: object\n",
      "22377    [Grim and Evil, Splatoon]\n",
      "Name: fandoms, dtype: object\n",
      "32360    [Las Vegas, Over the Hedge]\n",
      "Name: fandoms, dtype: object\n",
      "51085    [Total Drama series, Warriors]\n",
      "Name: fandoms, dtype: object\n",
      "14439    [Ashes to Ashes, Major Crimes]\n",
      "Name: fandoms, dtype: object\n",
      "29216    [Doc Martin, Thunderbirds]\n",
      "Name: fandoms, dtype: object\n",
      "12435    [Bakugan Battle Brawlers, Mana Khemia: Alchemi...\n",
      "Name: fandoms, dtype: object\n",
      "32660    [Summer I Turned Pretty, Bold and the Beautiful]\n",
      "Name: fandoms, dtype: object\n",
      "30128    [Dragon Heart, Gorillaz]\n",
      "Name: fandoms, dtype: object\n",
      "26320    [Adventures of Tintin, Hot Wheels: Battle Forc...\n",
      "Name: fandoms, dtype: object\n",
      "20373    [Five Nights at Freddy´s, Frozen]\n",
      "Name: fandoms, dtype: object\n",
      "28919    [Brady Bunch, Hellsing]\n",
      "Name: fandoms, dtype: object\n",
      "11484    [Fire Emblem, Warcraft]\n",
      "Name: fandoms, dtype: object\n",
      "16258    [Inception, Lord of the Flies]\n",
      "Name: fandoms, dtype: object\n",
      "40934    [Code Geass, Beelzebub/べるぜバブ]\n",
      "Name: fandoms, dtype: object\n",
      "4850    [Big Valley, Sons of Anarchy]\n",
      "Name: fandoms, dtype: object\n",
      "28008    [Lady and the Tramp, Fatal Fury]\n",
      "Name: fandoms, dtype: object\n",
      "17845    [Doctor Who, Red Dwarf]\n",
      "Name: fandoms, dtype: object\n",
      "24799    [Bully, SSX Tricky]\n",
      "Name: fandoms, dtype: object\n",
      "19158    [Burn Notice, Final Fantasy VII]\n",
      "Name: fandoms, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for count, index in enumerate(sample_indices):\n",
    "    id = df['3'][index]\n",
    "    index = dataset.index[dataset['id'] == id]\n",
    "    print(dataset['fandoms'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples = [0, 5, 10, 15, 20]\n",
    "res = []\n",
    "\n",
    "explainer = LimeTextExplainer(bow=True)\n",
    "explainerleft = MyLimeTextExplainer(bow=True, mode='left')\n",
    "explainerright = MyLimeTextExplainer(bow=True, mode='right')\n",
    "\n",
    "for count, index in enumerate(sample_indices):\n",
    "\n",
    "\n",
    "    label = df['labels'][index]\n",
    "    for s in subsamples:\n",
    "        cur_res = []\n",
    "\n",
    "        correct = False\n",
    "        segm = combine_segments_from_pd(index, s, 0) \n",
    "        #print(segm)\n",
    "        prediction = pipeline_onesegment(segm, mode='labels')\n",
    "        prediction = prediction[0]\n",
    "        orig_logits = pipeline_onesegment(segm, mode='logits')\n",
    "        if prediction == label:\n",
    "            correct = True\n",
    "\n",
    "        cur_res += index, s, segm, label, correct, orig_logits\n",
    "\n",
    "        \"\"\"if s == 0:\n",
    "            hcf = get_head_view_avg(segm, model1, tokenizer1)\n",
    "            with open(\"hc{}f.html\".format(index), \"w\") as file:\n",
    "                file.write(hcf.data)\n",
    "            hcu = get_head_view_avg(segm, model2, tokenizer2)\n",
    "            with open(\"hc{}u.html\".format(index), \"w\") as file:\n",
    "                file.write(hcu.data)\n",
    "            for layer in range(12):\n",
    "                hf = get_head_view(segm, model1, tokenizer1, layer)\n",
    "                with open(\"h{}_{}f.html\".format(index, layer), \"w\") as file:\n",
    "                    file.write(hf.data)\n",
    "                hu = get_head_view(segm, model2, tokenizer2, 11)\n",
    "                with open(\"h{}_{}u.html\".format(index, layer), \"w\") as file:\n",
    "                    file.write(hu.data)\n",
    "        \"\"\"\n",
    "        if prediction == 0:\n",
    "            exp = explainer.explain_instance(text_instance=segm, classifier_fn=pipeline_onesegment, num_features=10, num_samples=5000)\n",
    "            top_features = exp.as_list()\n",
    "            top_wordlist = []\n",
    "            top_weights = []\n",
    "            for f in top_features:\n",
    "                top_wordlist.append(f[0])\n",
    "            for word in top_wordlist:\n",
    "                segm_changed = segm.replace(word, \"\")\n",
    "                logits_changed = pipeline_onesegment(segm_changed, mode='logits')\n",
    "                #print(orig_logits[0], type(orig_logits[0]), logits_changed[0], type(logits_changed[0]))\n",
    "                weight = np.subtract(orig_logits[0], logits_changed[0])\n",
    "                top_weights.append({word: weight})\n",
    "\n",
    "            \"\"\"for word in top_wordlist:\n",
    "                segm = segm.replace(word, \"\")\n",
    "            exp = explainer.explain_instance(text_instance=segm, classifier_fn=pipeline_onesegment, num_features=10, num_samples=5000)\n",
    "            top_sec_features = exp.as_list()\n",
    "            top_sec_wordlist = []\n",
    "            for f in top_sec_features:\n",
    "                top_sec_wordlist.append(f[0])\"\"\"\n",
    "\n",
    "        if prediction == 1:\n",
    "\n",
    "            exp_l = explainerleft.explain_instance(text_instance=segm, classifier_fn=pipeline_onesegment, num_features=6, num_samples=5000)\n",
    "            top_features_l = exp_l.as_list()\n",
    "            top_wordlist = []\n",
    "            top_weights = []\n",
    "            for f in top_features_l:\n",
    "                top_wordlist.append(f[0])\n",
    "\n",
    "            exp_r = explainerright.explain_instance(text_instance=segm, classifier_fn=pipeline_onesegment, num_features=6, num_samples=5000)\n",
    "            top_features_r = exp_r.as_list()\n",
    "            for f in top_features_r:\n",
    "                top_wordlist.append(f[0])\n",
    "                \n",
    "            for word in top_wordlist:\n",
    "                segm_changed = segm.replace(word, \"\")\n",
    "                logits_changed = pipeline_onesegment(segm_changed, mode='logits')\n",
    "                #print(orig_logits[0], type(orig_logits[0]), logits_changed[0], type(logits_changed[0]))\n",
    "                weight = np.subtract(orig_logits[0], logits_changed[0])\n",
    "                top_weights.append({word: weight})\n",
    "\n",
    "            \"\"\"for word in top_wordlist:\n",
    "                segm = segm.replace(word, \"\")\n",
    "            exp = explainer.explain_instance(text_instance=segm, classifier_fn=pipeline_onesegment, num_features=10, num_samples=5000)\n",
    "            top_sec_features = exp.as_list()\n",
    "            top_sec_wordlist = []\n",
    "            for f in top_sec_features:\n",
    "                top_sec_wordlist.append(f[0])\"\"\"\n",
    "\n",
    "        cur_res += top_wordlist, top_features, top_weights\n",
    "\n",
    "        res.append(cur_res)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\" Sir, I have the the reports you\"ve asked for\" The bridge commander stated. \" Ahhh, thank you commander. Prep the fleet for the jump to Kashyyik\" Admiral Segutav ordered in his thick German accent. \" Yessir. Setting location now\" The commander replied. \" if I may ask sir, why did you need the reports on the Ghost\"s crew?\" \" I\"ve been put in charge of this fleet by none other than Grand Admiral Thrawn himself. He put me in command of this fleet with the sole purpose to destroy the Phoenix Squadron.$&*&*&$Hercules woke up when he heard Xena dreaming so he went and fetched some ale and put some sleeping poison in it. \"Xena, here take a drink.\" Hercules kindly demanded. \"Thank you, I think I need a drink.\" Xena replied. \"Xena, what was that all about?\" Hercules asked. \"I had a dream I was on Mount Olympus and Ares jumped out from somewhere with Gabrielle, then we started talking and all of a sudden he killed Gabrielle.\" Xena sobbed.',\n",
       " 0,\n",
       " True,\n",
       " array([[ 4.1582108, -4.244451 ]], dtype=float32),\n",
       " ['Segutav',\n",
       "  'Xena',\n",
       "  'Ahhh',\n",
       "  'I',\n",
       "  'Sir',\n",
       "  'Hercules',\n",
       "  'ordered',\n",
       "  'Yessir',\n",
       "  'Thank',\n",
       "  'replied'],\n",
       " [('Segutav', -0.4172649601340241),\n",
       "  ('Xena', -0.27764866366268015),\n",
       "  ('Ahhh', -0.17692358805464192),\n",
       "  ('I', -0.16901860233491572),\n",
       "  ('Sir', -0.13093255139109722),\n",
       "  ('Hercules', -0.1106918155774208),\n",
       "  ('ordered', -0.0876324958481001),\n",
       "  ('Yessir', -0.08416150300650703),\n",
       "  ('Thank', -0.08020145222810786),\n",
       "  ('replied', 0.05894641504772342)],\n",
       " [{'Segutav': array([ 7.6103687, -6.5250416], dtype=float32)},\n",
       "  {'Xena': array([-1.1145916,  1.1298003], dtype=float32)},\n",
       "  {'Ahhh': array([-0.49818182,  0.47477627], dtype=float32)},\n",
       "  {'I': array([ 0.6196306, -0.551337 ], dtype=float32)},\n",
       "  {'Sir': array([-0.6503434,  0.6286473], dtype=float32)},\n",
       "  {'Hercules': array([-0.6051874 ,  0.58823967], dtype=float32)},\n",
       "  {'ordered': array([ 0.7938595, -0.7076478], dtype=float32)},\n",
       "  {'Yessir': array([-0.44902372,  0.42178392], dtype=float32)},\n",
       "  {'Thank': array([ 0.28726006, -0.29658556], dtype=float32)},\n",
       "  {'replied': array([-1.3187771,  1.4551167], dtype=float32)}]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Sir, I have the the reports you\"ve asked for\" The bridge commander stated. \" Ahhh,\n",
      " thank you commander. Prep the fleet for the jump to Kashyyik\" Admiral Segutav \n",
      "ordered in his thick German accent. \" Yessir. Setting location now\" The commander replied. \" if I may ask sir, why did you need the reports on the \n",
      "Ghost\"s crew?\" \" \n",
      "I\"ve been put in charge of this fleet by none other than Grand Admiral Thrawn himself. He put me in command of this fleet with the sole purpose to destroy the Phoenix Squadron.\n",
      "$&*&*&$Hercules woke up when he heard Xena dreaming so he went\n",
      " and fetched some ale and put some sleeping poison in it. \"Xena, here take a drink.\" Hercules kindly demanded. \n",
      "\"Thank you, I think I need a drink.\" Xena replied. \"Xena, what was that all about?\" Hercules asked. \n",
      "\"I had a dream I was on Mount Olympus and Ares jumped out from somewhere with Gabrielle, then we started talking and all of a sudden he killed Gabrielle.\" Xena sobbed.\n",
      "Tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1ex [00:00, 999.60ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining embeddings...\n",
      "> processing item 0/1\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-3.4521582,  2.2805903]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segm = \"\"\"\" Sir, I have the the reports you\"ve asked for\" The bridge commander stated. \" Ahhh,\n",
    " thank you commander. Prep the fleet for the jump to Kashyyik\" Admiral Segutav \n",
    "ordered in his thick German accent. \" Yessir. Setting location now\" The commander replied. \" if I may ask sir, why did you need the reports on the \n",
    "Ghost\"s crew?\" \" \n",
    "I\"ve been put in charge of this fleet by none other than Grand Admiral Thrawn himself. He put me in command of this fleet with the sole purpose to destroy the Phoenix Squadron.\n",
    "$&*&*&$Hercules woke up when he heard Xena dreaming so he went\n",
    " and fetched some ale and put some sleeping poison in it. \"Xena, here take a drink.\" Hercules kindly demanded. \n",
    "\"Thank you, I think I need a drink.\" Xena replied. \"Xena, what was that all about?\" Hercules asked. \n",
    "\"I had a dream I was on Mount Olympus and Ares jumped out from somewhere with Gabrielle, then we started talking and all of a sudden he killed Gabrielle.\" Xena sobbed.\"\"\"\n",
    "\n",
    "#segm = combine_segments_from_pd(4433, 0, 0) \n",
    "print(segm)\n",
    "\n",
    "res = pipeline_onesegment(segm.replace(\"Segutav\", \"\"), mode=\"logits\")\n",
    "res\n",
    "#[ 4.5062966, -4.566842 ]\n",
    "#[ 4.1582108, -4.244451 ]\n",
    "#[-3.4521582,  2.2805903]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respd = pd.DataFrame (res, columns = ['text', 'label', 'correctness', 'logits', 'topwords', 'topwords_lime', 'topwords_obf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respd.to_csv('res_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Segutav': array([ 7.6103687, -6.5250416], dtype=float32)},\n",
       " {'Xena': array([-1.1145916,  1.1298003], dtype=float32)},\n",
       " {'Ahhh': array([-0.49818182,  0.47477627], dtype=float32)},\n",
       " {'I': array([ 0.6196306, -0.551337 ], dtype=float32)},\n",
       " {'Hercules': array([-0.6051874 ,  0.58823967], dtype=float32)},\n",
       " {'Sir': array([-0.6503434,  0.6286473], dtype=float32)},\n",
       " {'now': array([-0.01462936,  0.0202775 ], dtype=float32)},\n",
       " {'ordered': array([ 0.7938595, -0.7076478], dtype=float32)},\n",
       " {'Thank': array([ 0.28726006, -0.29658556], dtype=float32)},\n",
       " {'replied': array([-1.3187771,  1.4551167], dtype=float32)}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_onetext = pipeline_onetext(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_combined_texts_long(text_or_list):\n",
    "    \"\"\"\n",
    "    Get data from raw text that contains two fragments and a separater, or from a list of texts,\n",
    "    each of them containing two fragments and a separater. Used in pipeline_onetext. The ONLY type\n",
    "    of data processor for LIME inputs\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Getting data from raw text\")\n",
    "\n",
    "    datas = []\n",
    "\n",
    "    print(type(text_or_list), len(text_or_list))\n",
    "    if not isinstance(text_or_list, str):\n",
    "        for text_variant in text_or_list:\n",
    "            text1, text2 = text_variant.split(\"$&*&*&$\")\n",
    "            text1 = text_segmentate(text1, maxlen=750, seps='.?!;')\n",
    "            text2 = text_segmentate(text2, maxlen=750, seps='.?!;')\n",
    "            while len(text1) < 30 or len(text2) < 30:\n",
    "                    if len(text1) < 30:\n",
    "                        n_text1 = []\n",
    "                        for i in range(30):\n",
    "                            for sent in text1:\n",
    "                                n_text1.append(sent)\n",
    "                        text1 = n_text1\n",
    "                    elif len(text2) < 30:\n",
    "                        n_text2 = []\n",
    "                        for i in range(30):\n",
    "                            for sent in text2:\n",
    "                                n_text2.append(sent)\n",
    "                        text2 = n_text2\n",
    "            datas.append((text1, text2))\n",
    "    else:\n",
    "        text1, text2 = text_or_list.split(\"$&*&*&$\")\n",
    "        text1 = text_segmentate(text1, maxlen=750, seps='.?!;')\n",
    "        text2 = text_segmentate(text2, maxlen=750, seps='.?!;')\n",
    "        while len(text1) < 30 or len(text2) < 30:\n",
    "                if len(text1) < 30:\n",
    "                    n_text1 = []\n",
    "                    for i in range(30):\n",
    "                        for sent in text1:\n",
    "                            n_text1.append(sent)\n",
    "                    text1 = n_text1\n",
    "                elif len(text2) < 30:\n",
    "                    n_text2 = []\n",
    "                    for i in range(30):\n",
    "                        for sent in text2:\n",
    "                            n_text2.append(sent)\n",
    "                    text2 = n_text2\n",
    "        datas.append((text1, text2))\n",
    "    return datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from raw text\n",
      "<class 'str'> 42413\n"
     ]
    }
   ],
   "source": [
    "with open('textcomb3.txt', 'r') as text:\n",
    "    text3 = text.read()\n",
    "\n",
    "segments = get_data_from_combined_texts_long(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_segments(index, sep_option=0, write=False):\n",
    "    \"\"\"\n",
    "    Combine a pair of texts from dataset with a separator and turn into a single text\n",
    "    \"\"\"\n",
    "\n",
    "    text1 = segments[0][0][index]\n",
    "    text2 = segments[0][1][index]\n",
    "    sep = \"$&*&*&$\" if sep_option == 0 else \"[SEP]\"\n",
    "    text_combined = text1 + sep + text2\n",
    "    \n",
    "    if write:\n",
    "        name = \"textcomb{}.txt\".format(index)\n",
    "        with open(name, 'w') as textcomb:\n",
    "            textcomb.write(text_combined)\n",
    "\n",
    "    return(text_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rinoa noticed how there were so much dishes served, enough to feed one whole army. \"Please, take a seat.\" Laguna gestured at them as he sat at a chair placed at the end of the long table. He then looked around, as if looking for someone. \"Your son said he\"ll be joining us in a few minutes.\" Kiros plainly said. \"Ah...\" Laguna gave out a sheepish smile. \"Well, can\"t let our guests wait too long, can we? C\"mon now, gobble up! Don\"t be shy, just eat...$&*&*&$She even almost succeeded at her own assassination attempt at the crown prince, only to pull back and used a lame excuse as \"I do not do overtimes.\" when the battle ran for too long. But she did also express her intentions to leave her post as their hired mercenary afterwards when things got too senseless and chaotic with the Imperials. She was only in for the job and money, not for some loyalty or building a good name in her trade.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segm2 = combine_segments(1)\n",
    "segm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"DNA?\" Javier asked. The ME met his gaze, eyes twinkling. \"Oh yeah. And lots of it.\" \"Oh, I\"m listening,\" Ryan said with a grin. \"Well, there were male epithelials under her fabulously manicured nails, but I\"ve got at least three other donors.\" Ryan and Javier exchanged a look. \"Define donors,\" Ryan requested. \"I\"ve got saliva and semen,\" Lanie replied, checking the notes in the folder. \"Multiple donors for both too. From the looks of things our girl had multiple sexual partners just before she died.\" Ryan\"s eyebrow went up. \"Are you telling us this girl was in an orgy?\" \"Dude, Castle would love this,\" Javier couldn\"t help exclaiming. He shook his head as he and Ryan exchanged a look.[SEP]\"Are you insane?\" She\"d subconsciously taken a step closer to him. However, he mirrored her step backwards. \"I\"m not finished. You deserve more answers than that.\" This new found honesty shocked Sara enough to keep her mouth shut. However, he stopped, rubbing a hand over his face and sighing, partly in anger. \"Do you have any idea how much danger you\"re putting yourself in?\" he whispered to her, taking another step away and increasing the distance. \"When you didn\"t know, you could tell the truth. I don\"t want you to lie, Sara.\" They both knew it was pointless. He\"d involved her in his plan from day one. That\"s when it all started to slip into her mind, puzzle pieces falling snugly into place. \"I was a tool.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segm1 = combine_segments(0, 1)\n",
    "segm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What hospital are you at?\" Dustin said and there was a lot of rustling at the other end. \"The one near my house. I didn\"t catch the name I was a little occupied. Mary was throwing a fit.\" Joey answered sincerely. \"Kay, we are coming. See you in a few.\" Dustin said and the line went dead. Joey took a seat along the wall and waited for news about Mary. Just a tad bit of drama, hope its not too confusing. Blondie : P Oh gosh, sorry. I left you a cliff hanger. I wonder what will happen to Mary today.$&*&*&$She bobbed her head slightly from side to side and with a sheepish look remarked, \"Not exactly but something to the effect. I did call him a ninny though.\" John flashed his killer smile, it made her gooey every time. In an instant his eyes turned intense again and he rested his forehead on hers. The change in him didn\"t go unnoticed by Clarice. \"What?\" \"Clarice I...feel it again.\" He had told her about how he sometimes felt a foreboding feeling. \"Hey.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testtext16 = combine_segments_from_pd(0,16)\n",
    "testtext16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"OW!\" Mary yelled, jumping around, trying very hard not to curse or swear. \"Ow, mother flipping chicken poop.\" Mary yelled as she continued to yell and jump about.\\n \"Okay now it\"s time for you to go to the hospital.\" Joey said, knocked her knees out and picked her up in order to carry her downstairs into the kitchen for ice. \"Wow your lighter \\n then I remember. Have you not been eating?\" Joey asked, slightly alarmed. He could feel all of her bones through her clothes.$&*&*&$\"Are you okay?\" His simple inquiry about her \\n farewell touched her more than a well-worded lecture would have. So she softened a little. Distress quickly morphing into a bout of self-pity and embarrassment. \"What do you think?\" her face now  the \\nevidence of the strain she had been carrying for weeks. Her separation from Marcos made her achy and distressed. Her heart was breaking into a million\\n pieces every day as the distance between her and Marcos continued to widen. \"I think you need to talk to him.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testtext0_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She convinced the guard to let her through the gates and she ran up the familiar stairs until she got to the potted bush next to the front door, she reached \\ndown and pulled out the spare key Joey kept there for her. She used them to unlock the door and then tossed her bag down, leaving the door open, and ran upstairs \\ninto his room. She then fell down on his bed, held onto a pillow and cried so hard that she didn\"t even hear anyone enter the house. \"Mary!\" Joey yelled, standing \\ndumb-struck in the doorway.$&*&*&$\"Joh..n.\" her voice turned breathy, heat suffusing through her pores. A loud crash sounded behind them, echoing through the hall. \\nThey jerked apart and saw Marcos had accidentally dropped a cement block and created a hole in the floor while Lorna stood glaring at him. \\nThen she bit out,\"Nice going laser. As usual I\"ll have to fix your mess.\" Then proceeded to maneuver a few metals plates through the hole in an attempt to mend it.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testtext0_changed = \"\"\"\"OW!\" Mary yelled, jumping around, trying very hard not to curse or swear. \"Ow, mother flipping chicken poop.\" MARY yelled as she continued to yell and jump about.\n",
    " \"Okay now it\"s time for you to go to the hospital.\" Joey said, knocked her knees out and picked her up in order to carry her downstairs into the kitchen for ice. \"Wow your lighter \n",
    " then I remember. Have you not been eating?\" Joey asked, slightly alarmed. He could feel all of her bones through her clothes.$&*&*&$\"Are you okay?\" His simple inquiry about her \n",
    " farewell touched her more than a well-worded lecture would have. So she softened a little. Distress quickly morphing into a bout of self-pity and embarrassment. \"What do you think?\" her face now  the \n",
    "evidence of the strain she had been carrying for weeks. Her separation from Marcos made her achy and distressed. Her heart was breaking into a million\n",
    " pieces every day as the distance between her and Marcos continued to widen. \"I think you need to talk to him.\"\"\"\n",
    "\n",
    "\"\"\"She convinced the guard to let her through the gates and she ran up the familiar stairs until she got to the potted bush next to the front door, she reached \n",
    "down and pulled out the spare key Joey kept there for her. She used them to unlock the door and then tossed her bag down, leaving the door open, and ran upstairs \n",
    "into his room. She then fell down on his bed, held onto a pillow and cried so hard that she didn\"t even hear anyone enter the house. \"Mary!\" Joey yelled, standing \n",
    "dumb-struck in the doorway.$&*&*&$\"Joh..n.\" her voice turned breathy, heat suffusing through her pores. A loud crash sounded behind them, echoing through the hall. \n",
    "They jerked apart and saw Marcos had accidentally dropped a cement block and created a hole in the floor while Lorna stood glaring at him. \n",
    "Then she bit out,\"Nice going laser. As usual I\"ll have to fix your mess.\" Then proceeded to maneuver a few metals plates through the hole in an attempt to mend it.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from raw text\n",
      "<class 'str'> 963\n",
      "Tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1ex [00:00, 999.12ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining embeddings...\n",
      "> processing item 0/1\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-5.0536942,  4.766159 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pipeline_onesegment(testtext16, mode='logits')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from raw text\n",
      "<class 'str'> 949\n",
      "Tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1ex [00:00, 499.32ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining embeddings...\n",
      "> processing item 0/1\n",
      "Done!\n",
      "[[ 2.7647822 -3.1579168]]\n"
     ]
    }
   ],
   "source": [
    "testtext0_changed = testtext16.replace(\"Clarice\",\"\")\n",
    "\n",
    "\n",
    "res = pipeline_onesegment(testtext0_changed, mode='logits')\n",
    "print(res)\n",
    "\n",
    "\n",
    "#example 0-0 \n",
    "#[[ 4.7861366 -4.759954 ]] class 0 correct confidence 1\n",
    "#['She', 'MARY', 'and', 'proceeded', 'ran', 'bush']\n",
    "#without She (weight 0.28) [[ 4.1627555 -4.1556478]]\n",
    "#without MARY (weight 0.24) [[ 4.9938765 -5.0127206]] contrary to Lime!\n",
    "#if we replace MARY with Mary the difference becomes larger [[ 5.4506316 -5.633418 ]] which means that CASING MATTERS\n",
    "#if we replace MARY with JOHN texts get even more different [[ 5.380384 -5.513166]]. Keep increasing slightly if we add more JOHN\n",
    "#if we add JOHN to the second part as well, gets less different [[-4.439573  3.488577]]\n",
    "#without all topwords [[-2.9259872  1.8621671]] LABEL CHANGES\n",
    "\n",
    "#example 0-4\n",
    "#[ 1.371373 , -1.5087308] class 0 correct confidence 0.95\n",
    "#['bore', 'yelled', 'strain', 'worded', 'What', 'said']\n",
    "# without bore (weight 0.15) label SUDDENLY CHANGES [[-2.2827718  1.4593749]]\n",
    "# without worded (weight 0.14) label ALSO SUDDENLY CHANGES [[-1.9648905  1.2226754]]\n",
    "# without farewell (weight 0.12) ALSO [[-2.2466617  1.45032  ]], same for touched, said\n",
    "# and they somewhat combine: when we remove all 3 -- bigger changer [[-4.2394676  3.2303755]]\n",
    "# while without yelled (weight 0.11) it only goes in another direction [[ 2.6601286 -2.9694483]]\n",
    "# SO here the model very easily switches to class 1\n",
    "\n",
    "#example 0-16\n",
    "#[[-5.0536942,  4.766159 ]] class 1 incorrect confidence 1\n",
    "# however, it's enough to remove 1 name. Without Clarice (weight 0.26) [[ 2.7647822 -3.1579168]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm1 = \"\"\"Rinoa let out a soft giggle. \"Okay Uncle Laguna.\" \"As always, make yourselves at home!\" Kiros cleared his throat. \"Laguna, I believe our guests are hungry.\" \"OH! Yes yes, I\"m sorry.\" \n",
    "Laguna scratched the back of his neck in embarassment. \"To the dining hall we go!\" They all followed Laguna as he went through one of the sliding doors on the right side of the room. \n",
    "The dining hall was a plain one, though the lenghty table was pleasingly decorated with foods on the table.$&*&*&$The crown prince already entreated help from the glaives, a last resort he would \n",
    "rather not do as he did not want his father to be anymore involved. But they were heavily outnumbered, and their chances of surviving were slimming to none.\n",
    " It was when nea decided to show up with her own infantry jumping from her red ship. There was so much distrust towards her at first, knowing how long she had served the Emperor and carried out his orders.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm3 = \"\"\"\"\" Mary yelled, jumping around, trying very hard not to curse or swear. \"Ow, mother flipping chicken poop.\" Mary yelled as she continued to yell and jump about. \n",
    "\"Okay now it\"s time for you to go to the hospital.\" Joey said, knocked her knees out and picked her up in order to carry her downstairs into the kitchen for ice. \n",
    "\"Wow your lighter then I remember. Have you not been eating?\" Joey asked, slightly alarmed. He could feel all of her bones through her clothes.$&*&*&$\"Are you okay?\" \n",
    "His simple inquiry about her farewell touched her more than a well-worded lecture would have. So she softened a little. Distress quickly morphing into a bout of self-pity and embarrassment.\n",
    " \"What do you think?\" her face now bore the evidence of the strain she had been carrying for weeks. \n",
    "Her separation from Marcos made her achy and distressed. Her heart was breaking into a million pieces every day as the distance between her and Marcos continued to widen. \"I think you need to talk to him.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm4 = \"\"\"What hospital are you at?\" Dustin said and there was a lot of rustling at the other end. \"The one near my house, Clarice. I didn\"t catch the name I was a little occupied. \n",
    "Mary was throwing a fit.\" Joey answered sincerely. \"Kay, we are coming. See you in a few.\" Dustin said and the line went dead. Joey took a seat along the wall and waited for news about Mary.\n",
    " Just a tad bit of drama, hope its not too confusing. Blondie : P Oh gosh, sorry. I left you a cliff hanger. I wonder what will happen to Mary today.$&*&*&$Clarice bobbed her head slightly from side to side and with a sheepish look remarked,\n",
    "  \"Not exactly but something to the effect, Clarice. I did call him a ninny though.\" John flashed his killer smile, it made her gooey every time. In an instant his eyes turned intense again and he rested his forehead on hers. The change in him didn\"t go unnoticed by Clarice. \n",
    "\"What?\" \"Clarice I...feel it again.\" He had told her about how he sometimes felt a foreboding feeling. \"Hey.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from raw text\n",
      "<class 'str'> 929\n",
      "Tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1ex [00:00, 998.41ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining embeddings...\n",
      "> processing item 0/1\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-5.531711 ,  5.7830925]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pipeline_onesegment(segm1, mode='logits')\n",
    "res = [-5.531711 ,  5.7830925], [-5.3570204,  5.4185996]\n",
    "#Without Ara\n",
    "#shap prediction 1: 0.506, 0: -0.474\n",
    "#in reality 1: 0.364, 0: -0.175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from raw text\n",
      "<class 'str'> 990\n",
      "Tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1ex [00:00, 999.60ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining embeddings...\n",
      "> processing item 0/1\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-5.4629855,  5.5636225]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pipeline_onesegment(segm4, mode='logits')\n",
    "res\n",
    "#[-5.0536942,  4.766159 ]\n",
    "#One more Clarice [-5.1230087,  4.9003825]\n",
    "#Two more Clarice[-5.2671213,  5.1808963]\n",
    "#Third Clarice now in the first segment [-5.4629855,  5.5636225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from raw text\n",
      "<class 'str'> 987\n",
      "Tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1ex [00:00, 999.36ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining embeddings...\n",
      "> processing item 0/1\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00994844, -0.42599773]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pipeline_onesegment(segm3, mode='logits')\n",
    "res\n",
    "#[ 1.371373 , -1.5087308]\n",
    "#OW [ 2.905075 , -3.2013812]\n",
    "#! [ 2.2600317, -2.5298123]\n",
    "#OW! [-0.00994844, -0.42599773]\n",
    "#shap prediction OW for class 1 OW -0.305 ! -0.27\n",
    "#shap prediction OW for class 0 OW 0.303 ! 0.308\n",
    "#in reality for class 1 OW +1.54 ! +1.02 OW! -1.08\n",
    "#in reality for class 0 OW -1.53 ! -0.89 OW! 1.38 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rinoa let out a soft giggle. \"Okay Uncle Laguna.\" \"As always, make yourselves at home!\" Kiros cleared his throat. \"Laguna, I believe our guests are hungry.\" \"OH! Yes yes, I\"m sorry.\" Laguna scratched the back of his neck in embarassment. \"To the dining hall we go!\" They all followed Laguna as he went through one of the sliding doors on the right side of the room. The dining hall was a plain one, though the lenghty table was pleasingly decorated with foods on the table.$&*&*&$The crown prince already entreated help from the glaives, a last resort he would rather not do as he did not want his father to be anymore involved. But they were heavily outnumbered, and their chances of surviving were slimming to none. It was when Aranea decided to show up with her own infantry jumping from her red ship. There was so much distrust towards her at first, knowing how long she had served the Emperor and carried out his orders.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segm1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
