{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, 'Interpret-master')\n",
    "\n",
    "from dataset import NewsDataset\n",
    "from model import DistilBertForSequenceClassification\n",
    "\n",
    "from smooth_gradient import SmoothGradient\n",
    "from integrated_gradient import IntegratedGradient\n",
    "from saliency_interpreter import SaliencyInterpreter\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertConfig, DistilBertTokenizer\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(r\"..\\BertAA_content\\Model\\Checkpoints\\results_45000\\checkpoint-225000\")\n",
    "distilbert = transformers.AutoModelForSequenceClassification.from_pretrained(r\"..\\BertAA_content\\Model\\Checkpoints\\results_45000\\checkpoint-225000\")\n",
    "distilbert.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textl = \"\"\"\"OW!\" Mary yelled, jumping around, trying very hard not to curse or swear. \"Ow, mother flipping chicken poop.\" MARY yelled as she continued to yell and jump about.\n",
    " \"Okay now it\"s time for you to go to the hospital.\" Joey said, knocked her knees out and picked her up in order to carry her downstairs into the kitchen for ice. \"Wow your lighter \n",
    " then I remember. Have you not been eating?\" Joey asked, slightly alarmed. He could feel all of her bones through her clothes.\"\"\"\n",
    "textr = \"\"\"\"Are you okay?\" His simple inquiry about her \n",
    " farewell touched her more than a well-worded lecture would have. So she softened a little. Distress quickly morphing into a bout of self-pity and embarrassment. \"What do you think?\" her face now  the \n",
    "evidence of the strain she had been carrying for weeks. Her separation from Marcos made her achy and distressed. Her heart was breaking into a million\n",
    " pieces every day as the distance between her and Marcos continued to widen. \"I think you need to talk to him.\"\"\"\n",
    "\n",
    "text = textl + \" [SEP] \" + textr\n",
    "\n",
    "\n",
    "t = tokenizer(text, truncation=True, padding='max_length', max_length=255, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert.eval()\n",
    "with torch.no_grad():\n",
    "    output = distilbert(**t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = t[0].ids\n",
    "type_ids = t[0].type_ids\n",
    "attention_mask = t[0].attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {'input_ids': torch.tensor(ids), 'token_type_ids': torch.tensor(type_ids), 'attention_mask': torch.tensor(attention_mask), 'labels': torch.tensor(1)}\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    [input],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = [\n",
    "    [\"Interpretation of HuggingFase's model decision\"], \n",
    "    [\"Transformer-based models have taken a leading role \"\n",
    "     \"in NLP today.\"]\n",
    "]\n",
    "\n",
    "test_dataset = NewsDataset(\n",
    "    data_list=test_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=256, \n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert.to('cpu')\n",
    "distilbert.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        #print(batch)\n",
    "\n",
    "        #batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = distilbert(**batch, output_hidden_states=True)\n",
    "        cur_logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        print(outputs, type(outputs), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_grad = IntegratedGradient(\n",
    "    distilbert, \n",
    "    criterion, \n",
    "    tokenizer, \n",
    "    show_progress=False,\n",
    "    encoder=\"bert\"\n",
    ")\n",
    "instances = integrated_grad.saliency_interpret(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = [\n",
    "    [\"Interpretation of HuggingFase's model decision\"], \n",
    "    [\"Transformer-based models have taken a leading role \"\n",
    "     \"in NLP today.\"]\n",
    "]\n",
    "\n",
    "test_dataset = NewsDataset(\n",
    "    data_list=test_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=config.max_position_embeddings, \n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import shap\n",
    "\n",
    "# load a transformers pipeline model\n",
    "model = transformers.pipeline('sentiment-analysis', return_all_scores=True)\n",
    "\n",
    "# explain the model on two sample inputs\n",
    "explainer = shap.Explainer(model) \n",
    "shap_values = explainer([\"What a great movie! ...if you have no taste.\"])\n",
    "\n",
    "# visualize the first prediction's explanation for the POSITIVE output class\n",
    "shap.plots.text(shap_values[0, :, \"POSITIVE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm00 = \"\"\"She convinced the guard to let her through the gates and she ran up the familiar stairs until she got to the potted bush next to the front door, she reached down and pulled out the spare key Joey kept there for her.\n",
    " She used them to unlock the door and then tossed her bag down, leaving the door open, and ran upstairs into his room. She then fell down on his bed, held onto a pillow and cried so hard that she didn\"t even hear anyone enter the house.\n",
    "  \"MARY!\" Joey yelled, standing dumb-struck in the doorway. \"Mary? Mary are you okay? Mary whats wrong?\" Joey asked, crossing the room and trying to pry the pillow from her clutches. \"Joey?\" Mary blubbered. \n",
    "  \"You aren\"t supposed to be back for another two days.[SEP]\"Joh..n.\" her voice turned breathy, heat suffusing through her pores. A loud crash sounded behind them, echoing through the hall. They jerked apart \n",
    "  and saw Marcos had accidentally dropped a cement block and created a hole in the floor while Lorna stood glaring at him. Then she bit out,\"Nice going laser. As usual I\"ll have to fix your mess.\" \n",
    "  Then proceeded to maneuver a few metals plates through the hole in an attempt to mend it. Marcos lifted his palms, blinding yellow light emitted from his palms and welded the metal into the floor, \n",
    "  filling the hole. With a tortured glance at Lorna he remarked, \"I fix my own messes. You don\"t have to worry about them from now on.\" Then he sauntered away.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm00short = \"\"\"She convinced the guard to let her through the gates and she ran up the familiar stairs until she got to the potted bush next to the front door, \n",
    "she reached down and pulled out the spare key Joey kept there for her. She used them to unlock the door and then tossed her bag down, leaving the door open, and ran upstairs into his room. \n",
    "She then fell down on his bed, held onto a pillow and cried so hard that she didn\"t even hear anyone enter the house. \"MARY!\" Joey yelled, standing dumb-struck in the doorway.[SEP]\"Joh..n.\" \n",
    "her voice turned breathy, heat suffusing through her pores. A loud crash sounded behind them, echoing through the hall. They jerked apart and saw Marcos had accidentally dropped a cement block and created a hole in the floor while Lorna stood glaring at him. \n",
    "Then she bit out,\"Nice going laser. As usual I\"ll have to fix your mess.\" Then proceeded to maneuver a few metals plates through the hole in an attempt to mend it.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm10 = \"\"\"\"DNA?\" Javier asked. The ME met his gaze, eyes twinkling. \"Oh yeah. And lots of it.\" \"Oh, I\"m listening,\" Ryan said with a grin. \"Well, there were male epithelials under her fabulously manicured nails, \n",
    "but I\"ve got at least three other donors.\" Ryan and Javier exchanged a look. \"Define donors,\" Ryan requested. \"I\"ve got saliva and semen,\" Lanie replied, checking the notes in the folder. \"Multiple donors for both too. \n",
    "From the looks of things our girl had multiple sexual partners just before she died.\" Ryan\"s eyebrow went up. \"Are you telling us this girl was in an orgy?\" \"Dude, Castle would love this,\" Javier couldn\"t help exclaiming. \n",
    "He shook his head as he and Ryan exchanged a look.[SEP]\"Are you insane?\" She\"d subconsciously taken a step closer to him. However, he mirrored her step backwards. \"I\"m not finished. You deserve more answers than that.\" \n",
    "This new found honesty shocked Sara enough to keep her mouth shut. However, he stopped, rubbing a hand over his face and sighing, partly in anger. \"Do you have any idea how much danger you\"re putting yourself in?\" he\n",
    " whispered to her, taking another step away and increasing the distance. \"When you didn\"t know, you could tell the truth. I don\"t want you to lie, Sara.\" They both knew it was pointless. He\"d involved her in his plan from day one.\n",
    "  That\"s when it all started to slip into her mind, puzzle pieces falling snugly into place. \"I was a tool.'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(r\"..\\BertAA_content\\Model\\Checkpoints\\results_45000\\checkpoint-225000\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(r\"..\\BertAA_content\\Model\\Checkpoints\\results_45000\\checkpoint-225000\")\n",
    "\n",
    "#model = transformers.AutoModelForSequenceClassification.from_pretrained(r\"..\\BertAA_content\\Model\\Checkpoints\\results4\\checkpoint-180000\")\n",
    "#tokenizer = transformers.AutoTokenizer.from_pretrained(r\"..\\BertAA_content\\Model\\Checkpoints\\results4\\checkpoint-180000\")\n",
    "\n",
    "def f(pairs):\n",
    "    outs = []\n",
    "    for q in pairs:\n",
    "        text1, text2 = q.split(\"[SEP]\")\n",
    "        d = tokenizer(text1, text2, truncation=True, padding='max_length', max_length=255, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            out = model(**d)\n",
    "        logits = out.logits\n",
    "        outs.append(logits.reshape(-1).detach().numpy())\n",
    "    return outs\n",
    "\n",
    "# attach a dynamic output_names property to the models so we can plot the tokens at each output position\n",
    "def out_names(inputs):\n",
    "    text1, text2 = inputs.split(\"[SEP]\")\n",
    "    d = tokenizer(text1, text2, truncation=True, padding='max_length', max_length=255)\n",
    "    return [tokenizer.decode([id]) for id in d[\"input_ids\"]]\n",
    "\n",
    "f.output_names = out_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results of LIME analysis\n",
    "import pandas as pd\n",
    "respd = pd.read_csv(\"res_100.csv\")\n",
    "texts = respd['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(f, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaps = []\n",
    "for index, text in enumerate(texts):\n",
    "    shaptext = text.replace(\"$&*&*&$\", \"[SEP]\")\n",
    "    explainer = shap.Explainer(f, tokenizer)\n",
    "    shap_values = explainer([shaptext])\n",
    "    shaps.append([shaptext, shap_values])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_shaps(shaps, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_shaps(shaps, start, end):\n",
    "    cur_shaps = shaps[start:end]\n",
    "    for i, exp in enumerate(cur_shaps): \n",
    "        exp_label = int(respd['label'][i])\n",
    "        print(\"Explanation #{}, label {}\".format(i, exp_label))\n",
    "        shap.plots.text(exp[1][0, :, exp_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shaps[1].base_values[0]\n",
    "\n",
    "label = np.argmax(shaps[1].base_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (1,3,5):\n",
    "    shap.plots.text(shaps[i][0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=pipe([segm00])\n",
    "print(prediction[0])\n",
    "type(prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = f2([segm00])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in tokenizer(\"JOHN\")[\"input_ids\"]:\n",
    "    print(tokenizer.decode([id])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm1 = \"\"\"Rinoa let out a soft giggle. \"Okay Uncle Laguna.\" \"As always, make yourselves at home!\" Kiros cleared his throat. \"Laguna, I believe our guests are hungry.\" \"OH! Yes yes, I\"m sorry.\" \n",
    "Laguna scratched the back of his neck in embarassment. \"To the dining hall we go!\" They all followed Laguna as he went through one of the sliding doors on the right side of the room. \n",
    "The dining hall was a plain one, though the lenghty table was pleasingly decorated with foods on the table.[SEP]The crown prince already entreated help from the glaives, a last resort he would \n",
    "rather not do as he did not want his father to be anymore involved. But they were heavily outnumbered, and their chances of surviving were slimming to none.\n",
    " It was when Aranea decided to show up with her own infantry jumping from her red ship. There was so much distrust towards her at first, knowing how long she had served the Emperor and carried out his orders.\"\"\"\n",
    "segm2 = \"\"\"Rinoa noticed how there were so much dishes served, enough to feed one whole army. \"Please, take a seat.\" Laguna gestured at them as he sat at a chair placed at the end of the long table. He then looked around, as if looking for someone. \n",
    "\"Your son said he\"ll be joining us in a few minutes.\" Kiros plainly said. \"Ah...\" Laguna gave out a sheepish smile. \"Well, can\"t let our guests wait too long, can we? C\"mon now, gobble up! Don\"t be shy, just eat...[SEP]She even almost succeeded\n",
    " at her own assassination attempt at the crown prince, only to pull back and used a lame excuse as \"I do not do overtimes.\" when the battle ran for too long. \n",
    "But she did also express her intentions to leave her post as their hired mercenary afterwards when things got too senseless and chaotic with the Imperials. She was only in for the job and money, not for some loyalty or building a good name in her trade.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm3 = \"\"\"\"OW!\" Mary yelled, jumping around, trying very hard not to curse or swear. \"Ow, mother flipping chicken poop.\" Mary yelled as she continued to yell and jump about. \n",
    "\"Okay now it\"s time for you to go to the hospital.\" Joey said, knocked her knees out and picked her up in order to carry her downstairs into the kitchen for ice. \n",
    "\"Wow your lighter then I remember. Have you not been eating?\" Joey asked, slightly alarmed. He could feel all of her bones through her clothes.[SEP]\"Are you okay?\" \n",
    "His simple inquiry about her farewell touched her more than a well-worded lecture would have. So she softened a little. Distress quickly morphing into a bout of self-pity and embarrassment.\n",
    " \"What do you think?\" her face now bore the evidence of the strain she had been carrying for weeks. \n",
    "Her separation from Marcos made her achy and distressed. Her heart was breaking into a million pieces every day as the distance between her and Marcos continued to widen. \"I think you need to talk to him.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm4 = \"\"\"What hospital are you at?\" Dustin said and there was a lot of rustling at the other end. \"The one near my house. I didn\"t catch the name I was a little occupied. \n",
    "Mary was throwing a fit.\" Joey answered sincerely. \"Kay, we are coming. See you in a few.\" Dustin said and the line went dead. Joey took a seat along the wall and waited for news about Mary.\n",
    " Just a tad bit of drama, hope its not too confusing. Blondie : P Oh gosh, sorry. I left you a cliff hanger. I wonder what will happen to Mary today.[SEP]She bobbed her head slightly from side to side and with a sheepish look remarked,\n",
    "  \"Not exactly but something to the effect. I did call him a ninny though.\" John flashed his killer smile, it made her gooey every time. In an instant his eyes turned intense again and he rested his forehead on hers. The change in him didn\"t go unnoticed by Clarice. \n",
    "\"What?\" \"Clarice I...feel it again.\" He had told her about how he sometimes felt a foreboding feeling. \"Hey.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm3_altered = \"\"\"\"OW!\" Mary yelled, jumping around, trying very hard not to curse or swear. \"Ow, mother flipping chicken poop.\" Mary yelled as she continued to yell and jump about. \n",
    "\"Okay now it\"s time for you to go to the hospital.\" Joey said, knocked her knees out and picked her up in order to carry her downstairs into the kitchen for ice. \n",
    "\"Wow your lighter then I remember. Have you not been eating?\" Joey asked, slightly alarmed. He could feel all of her bones through her clothes.[SEP]\"Are you okay?\" \n",
    "His simple inquiry about her farewell touched her more than a well-worded lecture would have. So she softened a little. Distress quickly morphing into a bout of self-pity and embarrassment.\n",
    " \"What do you think?\" her face now  the evidence of the strain she had been carrying for weeks. \n",
    "Her separation from Marcos made her achy and distressed. Her heart was breaking into a million pieces every day as the distance between her and Marcos continued to widen. \"I think you need to talk to him.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm4_altered = \"\"\"What hospital are you at?\" Dustin said and there was a lot of rustling at the other end. \"The one near my house. I didn\"t catch the name I was a little occupied. \n",
    "Mary was throwing a fit.\" Joey answered sincerely. \"Kay, we are coming. See you in a few.\" Dustin said and the line went dead. Joey took a seat along the wall and waited for news about Mary.\n",
    " Just a tad bit of drama, hope its not too confusing. Blondie : P Oh gosh, sorry. I left you a cliff hanger. I wonder what will happen to Mary today.[SEP]She bobbed her head slightly from side to side and with a sheepish look remarked,\n",
    "  \"Not exactly but something to the effect. I did call him a ninny though.\" John flashed his killer smile, it made her gooey every time. In an instant his eyes turned intense again and he rested his forehead on hers. The change in him didn\"t go unnoticed by . \n",
    "\"What?\" \" I...feel it again.\" He had told her about how he sometimes felt a foreboding feeling. \"Hey.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm1_corrected = \"\"\"Rinoa let out a soft giggle. \"Okay Uncle Laguna.\" \"As always, make yourselves at home!\" Kiros cleared his throat. \"Laguna, I believe our guests are hungry.\" \"OH! Yes yes, I\"m sorry.\" \n",
    "Laguna scratched the back of his neck in embarrassment. \"To the dining hall we go!\" They all followed Laguna as he went through one of the sliding doors on the right side of the room. \n",
    "The dining hall was a plain one, though the lengthy table was pleasingly decorated with foods on the table.[SEP]The crown prince already entreated help from the glaives, a last resort he would \n",
    "rather not do as he did not want his father to be anymore involved. But they were heavily outnumbered, and their chances of surviving were slimming to none.\n",
    " It was when Aranea decided to show up with her own infantry jumping from her red ship. There was so much distrust towards her at first, knowing how long she had served the Emperor and carried out his orders.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm4433 = \"\"\"\" Sir, I have the the reports you\"ve asked for\" The bridge commander stated. \"\n",
    " Ahhh, thank you commander. Prep the fleet for the jump to Kashyyik\" Admiral Segutav ordered in \n",
    " his thick German accent. \" Yessir. Setting location now\" The commander replied. \" if I may ask sir, \n",
    " why did you need the reports on the Ghost\"s crew?\" \" I\"ve been put in charge of this fleet by none other than \n",
    " Grand Admiral Thrawn himself. He put me in command of this fleet with the sole purpose to destroy the Phoenix\n",
    "  Squadron.[SEP]Hercules woke up when he heard Xena dreaming so he went and fetched some ale and put some\n",
    "   sleeping poison in it. \"Xena, here take a drink.\" Hercules kindly demanded. \"Thank you, I think I need a drink.\" \n",
    "   Xena replied. \"Xena, what was that all about?\" Hercules asked. \"I had a dream I was on Mount Olympus and Ares jumped \n",
    "   out from somewhere with Gabrielle, \n",
    "then we started talking and all of a sudden he killed Gabrielle.\" Xena sobbed.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [segm4433]\n",
    "\n",
    "explainer_start = shap.Explainer(f, tokenizer)\n",
    "shap_values = explainer_start(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [segm3_altered]\n",
    "\n",
    "explainer_start = shap.Explainer(f, tokenizer)\n",
    "shap_values3 = explainer_start(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [segm4]\n",
    "\n",
    "explainer_start = shap.Explainer(f, tokenizer)\n",
    "shap_values4 = explainer_start(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [segm4_altered]\n",
    "\n",
    "explainer_start = shap.Explainer(f, tokenizer)\n",
    "shap_values41 = explainer_start(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [segm00]\n",
    "\n",
    "explainer_start = shap.Explainer(f, tokenizer)\n",
    "shap_values_long_00 = explainer_start(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values_long_00[0, :, 0])\n",
    "#short, regular model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values_long_00[0, :, 0])\n",
    "#long, big model 180k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values_long_00[0, :, 0])\n",
    "#long, big model 450k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values_long_00[0, :, 0])\n",
    "#long, big model 450k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local explanation for your first example\n",
    "shap.plots.text(shap_values_start[0, :, 1])\n",
    "# global summary explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[0, :, 1])\n",
    "#corrected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[0, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[0, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values3[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values4[0, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values41[0, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[0, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_couplt.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values[0, :, 0], max_display=20, order=shap.Explanation.argsort.flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values_start[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "96d7c5f1ded37e429f197635c2bd0274735efde1a7acd6754cdde172eae465e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
